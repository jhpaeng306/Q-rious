
# Single shot Quantum Neural Network
#### QHack2023 Open Hackathon. Team name : Q-rious


## Project description
In our project, we built the Quantum Neural Network that works with only single shot by assigning wavefunction to lables. Our Quantum Neural Network classifies among $m$ labels, and is composed with two parts. 

![3](https://user-images.githubusercontent.com/124068470/221957508-92934c40-358e-4cd0-9ead-e4079d25e8b7.png)

### Assigning the wavefunction : $U(x, w, b)$

The front part of our circuit assigns the input data to a quantum state $U(x, w, b) \|000....00\rangle$, which corresponds to the correct label.
Here, $w$ and $b$ are parameters being tuned during the learning process, and $x$ is parameter containing information about the input data.
Each label is matched to some quantum state automatically during the learning process.
The circuit learns under the rule that the quantum state made by $U(x, w, b)$ and $U(y, w, b)$ should be orthogonal if the label of two data $x$ and $y$ are different, while the size of inner product should be one if the label of $x$ and $y$ are identical. Determining the size of inner product is quite simple, as it is the probabilty of $\|000....00\rangle$ state for following circuit.

![preFuncPair](https://user-images.githubusercontent.com/124068470/221955848-55662ebd-9333-44eb-b27e-19bcc4b0366e.png)

Under this rule, if two data $x^A$ and $x^B$ are classified as the same label($A=B$) and two data $x^B$ and $x^C$ are classified as the different label($B\neq C$), then $x^A$ and $x^C$ are automatically classified as different classes, $A \neq C$, since the quantum states generated by $U(x, w, b)$ corresponding to labels $A$ and $B$ only differ by the phase. 

This characteristics allows a new learning scheme. Originally, when making a classifier with the classical neural network, each label is arbitrarily assigned to some one-hot or indication vector, and the output of the neural network finds the closest one to find the label. However, such matching system is quite insufficient, in the sense that there are a numerous ways to assign the vectors to labels, while the optimal assignment is unknown.

To avoid this problem, we may choose a different loss function with two sets of data by $x^A, x^B$ as input, and design to have a smaller output as the similarity between $x^A, x^B$ coincides with the output of neural network by $x^A$ and $x^B$. However, this approach needs many training sets, since the classical neural network does not recognize that $A\neq C$ if $A=B$ and $B\neq C$. 

However, for Quantum Neural Network, especially when the network can classify by single shot, such problem disappears. For two wavefunctions to be distinguishable by the measurement, especially by the single shot, they should be orthogonal, which means for quantum classifier, wavefunction resulting from neural network should be orthogonal for different label. If we additionally give condition that the absolute value of the inner product between wavefucntions resulting from the same label is $1$, the number of dataset needed for learning sameness and difference can reduce dramatically, because when $A=B$ and $\sim B=C$, $\sim A=C$ hold for this scheme.

The ansatz for $U(x, w, b)$ is given as follows.
![preFunc](https://user-images.githubusercontent.com/124068470/221949350-a31aa87a-73ca-4cc5-b911-7732e592ed72.png)

### Measuring : $V(\lambda)$
Although the states are perfectly classified by assigning wavefunctions, we can't see the result. Appropriate measurement is needed to see the result. Any measurement is equivalent with applying a unitary transform and measuring qubits. The back part of our circuit finds this unitary transform. We use the same ansatz, with parameters independent with the data.

Since the resulting states with the data of same labels are similar, learning for whole dataset is not needed. Only one or partial number of data from each label are required to determine the parameters. Also, since the states with different labels are orthogonal, appropriate measurement that distinguishes label by a single shot should exist.



## Code and File description
* `generator.py` generates dataSet used for learning from `iris.csv`. 
* `simple_iris.csv` contains essential comparisons. 
* `preLearning.py` optimizes $U(x, w, b)$ and `postLearning.py` optimizes $V(\lambda)$. Optimization results are saved as `saveBias.txt`, `savePost.txt`, `saveWeight.txt`.
* `getOutput.py` has functions giving probabilities or single shot results of the full Circuit. Based on the probabilities, best classificaiton criteria was chosen. The classification result is saved in `classificationResult.txt`. Due to the lack of time, our results are not complete. For most cases Setosa is correctly classified to Setosa by single shot. Howeveer, other cases are misclassified to Setosa with about 30% of probability.



